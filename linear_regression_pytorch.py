# -*- coding: utf-8 -*-
"""Untitled0.ipynb
Automatically generated by Colab.
Original file is located at
    https://colab.research.google.com/drive/1hLuQjzxVvMaSDiJ1dHQgkFK8VCUXV4x-
"""
import torch
 
x = torch.tensor(3.)
w = torch.tensor(4., requires_grad=True)
b = torch.tensor(5., requires_grad=True)
y = w * x + b
y
y.backward()
print('dy/dx', x.grad)
print('dy/dw', w.grad)
print('dy/db', b.grad)
import numpy as np
import torch
#region, temp,rain,humidity,apples,oranges
#kanto, 73, 67, 43, 56, 70
#johto, 91, 88, 64 ,81, 101
#hoen, 87, 134, 58, 119, 133
#sinnoh, 102, 43,37, 22, 37
#unova, 69, 96, 70, 103, 119
#yield_apple = w11 * temp + w12 * rainfall + w13 * humidity + b1
#yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2
x = np.array([[1,2],[3,4.]])
x
y = torch.from_numpy(x)
y
x.dtype, y.dtype
inputs = np.array([[73,67,43],
 [91,88,64],
[ 87,134,58],
[102,43,37],
 [69,96,70]], dtype='float32')
targets = np.array([[56,70],
[81,101],
[119,133],
[22,37],
[103,119]], dtype='float32')
inputs = torch.from_numpy(inputs)
targets = torch.from_numpy(targets)
print(inputs)
print(targets)
w = torch.randn(3,2,requires_grad=True)
b = torch.randn(2,requires_grad=True)
print(w)
print(b)
"""torch.randn creates a tensor with the given shape, with elements pickedrandomly from a normal distribution with mean 0 and stand deviation 1.
Model is a function that performs a matrix multiplication of the inputs and the weights w (transposed) and adds the bias b (replicated for each observation)
"""
def model(x):
    w = torch.randn(2,3,requires_grad=True)
    b = torch.randn(2,requires_grad=True)
    return x @ w.t() + b
"""@ represents matrix mulitiplication, and .t metod returns transpose of a tensor.
matrix obtained by passing the input data into the model is a set of predictions for the target vars.
"""
preds = model(inputs)
print(preds)
diff = preds - targets
print(diff)
diff_sqr = diff * diff
print(diff_sqr)
torch.sum(diff_sqr) / diff.numel()
def mse(t1,t2):
  diff = t1 - t2
  return torch.sum(diff * diff) / diff.numel()
"""torch.sum returns sum of all elemnts in tensor and .nume1 method returns the nummber of elements in a tensor"""
loss = mse(preds, targets)
print(loss)
loss.backward()
print(w)
print(w.grad)
"""gradients are stored in the .grad property of the respective tensors. Note derivative of the loss w.r.t. the weights matrix is itself a matrix, with same dimentsion"""
print(b)
print(b.grad)